#Sample config.properties. In production config.properties at /mnt/models/config/config.properties will be used
inference_address=http://0.0.0.0:8080
management_address=http://0.0.0.0:8081
metrics_address=http://0.0.0.0:8082
enable_envvars_config=true


# make false or it's taking so much time üëÄ‚è≥ü•±
install_py_dep_per_model=false

load_models=all
max_response_size=655350000
model_store=model_store
workflow_store=model_store
default_response_timeout=600
async_logging=true
disable_token_authorization=true
enable_model_api=true

#### don't increase model copy per worker "overhead". so, system out of error
min_workers=1
max_workers=1


batch_size=10
default_workers_per_model=1
enable_metrics_api=true
metrics_mode=prometheus
job_queue_size=50


# serialize below json and test it
# model_snapshot={"name":"startup.cfg","modelCount":1,"models":{"sd3":{"1.0":{"defaultVersion":true,"minWorkers":2,"maxWorkers":4,"batchSize":8,"maxBatchDelay":10,"responseTimeout":600}}}}

# model_snapshot = {
#     "name":"startup.cfg", 
#     "modelCount":1,
#     "models":{
#         "sd3":{
#             "1.0":{
#                 "defaultVersion":true,
#                 "marName":"sd3.mar",
#                 "minWorkers":2,
#                 "maxWorkers":4,
#                 "batchSize":8,
#                 "maxBatchDelay":10,
#                 "responseTimeout":600
#             }
#         }
#     }
# }

# number_of_gpu=1
# model_snapshot={"name": "startup.cfg","modelCount": 1,"models": { "sd3": { "1.0": {"defaultVersion": true,"marName": "sd3.mar", "minWorkers": 1, "maxWorkers": 1,"batchSize": 10,    "maxBatchDelay": 100,  "responseTimeout": 600,  "startupTimeout": 120, } } }}